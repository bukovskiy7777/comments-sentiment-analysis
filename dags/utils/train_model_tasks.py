import logging
import os
from airflow.decorators import task
from airflow.providers.postgres.hooks.postgres import PostgresHook
import pandas as pd
import joblib
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, mean_absolute_error

@task
def train_sentiment_model(EXPERIMENT_NAME, ds=None, **context):
    # yesterday_ds = context['macros'].ds_add(ds, -1)
    yesterday_ds = ds

    pg_hook = PostgresHook(postgres_conn_id='postgres_ubuntu')
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—Å–≤—è–∑—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å –µ–≥–æ –º–µ—Ç–∫–æ–π –∏ —Å–∫–æ—Ä–æ–º)
    query = """
        SELECT c.text_display, s.label, s.score 
        FROM youtube_comments c
        JOIN comment_sentiment s ON c.comment_id = s.comment_id
    """
    df = pg_hook.get_pandas_df(query)

    n_samples = len(df)
    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –Ω–µ –±–æ–ª–µ–µ 50% –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –Ω–æ –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
    calculated_max_features = min(10000, max(1000, n_samples // 2))
    
    if len(df) < 20:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        logging.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.")
        return
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (positive, neutral, negative)
    # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏)
    X = df['text_display']
    Y = df[['label', 'score']]

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: 80% –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ, 20% –Ω–∞ —Ç–µ—Å—Ç
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º random_state –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    X_train, X_test, y_train, y_test = train_test_split(
        X, 
        Y, 
        test_size=0.2, 
        random_state=42,
        stratify=Y['label'] # –ß—Ç–æ–±—ã –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ (pos/neg) –±—ã–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã –≤ –æ–±–µ–∏—Ö —á–∞—Å—Ç—è—Ö
    )

    y_train_class = y_train['label']
    y_test_class = y_test['label']

    y_train_reg = y_train['score']   
    y_test_reg = y_test['score']

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    mlflow.set_tracking_uri("http://localhost:5000") # –ò–ª–∏ –ø—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ
    mlflow.set_experiment(EXPERIMENT_NAME)

    with mlflow.start_run(run_name=f"train_{yesterday_ds}"):
        # --- –ß–∞—Å—Ç—å 1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (Label) ---
        class_pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(max_features=calculated_max_features, stop_words='english')),
            ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))
        ])
        
        class_pipeline.fit(X_train, y_train_class)
        y_pred_class = class_pipeline.predict(X_test)
        # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±–µ–∏—Ö —á–∞—Å—Ç—è—Ö
        acc_test = accuracy_score(y_test_class, y_pred_class)
        acc_train = accuracy_score(y_train_class, class_pipeline.predict(X_train))
        f1 = f1_score(y_test_class, y_pred_class, average='weighted')
        
        # --- –ß–∞—Å—Ç—å 2: –†–µ–≥—Ä–µ—Å—Å–∏—è (Score) ---
        reg_pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(max_features=calculated_max_features, stop_words='english')),
            ('reg', Ridge())
        ])
        
        reg_pipeline.fit(X_train, y_train_reg)
        y_pred_reg = reg_pipeline.predict(X_test)
        # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±–µ–∏—Ö —á–∞—Å—Ç—è—Ö
        mse_test = mean_squared_error(y_test_reg, y_pred_reg)
        mse_train = mean_squared_error(y_train_reg, reg_pipeline.predict(X_train))

        mae = mean_absolute_error(y_test_reg, y_pred_reg)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow
        mlflow.log_param("model_type", "tfidf_logistic_ridge")
        mlflow.log_param("max_features", calculated_max_features)
        
        mlflow.log_metric("accuracy_train", acc_train)
        mlflow.log_metric("accuracy_test", acc_test)
        mlflow.log_metric("mse_train", mse_train)
        mlflow.log_metric("mse_test", mse_test)
        # –¢–∞–∫–∂–µ –ø–æ–ª–µ–∑–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É (Overfitting Ratio)
        mlflow.log_metric("acc_gap", abs(acc_test - acc_train))
        mlflow.log_metric("mse_gap", abs(mse_test - mse_train))

        mlflow.log_metric("f1_score", f1)
        mlflow.log_metric("mae_score", mae)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        mlflow.sklearn.log_model(class_pipeline, "classifier_model")
        mlflow.sklearn.log_model(reg_pipeline, "regressor_model")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∏–∑ FastAPI
        model_path = "/home/oleksandr/apps/comments-sentiment-analysis/models/sentiment_models_bundle.pkl"
        #model_path = "/home/oleksandr/apps/comments-sentiment-analysis/models/sentiment_model.pkl"
        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        model_pack = {
            'classifier': class_pipeline,
            'regressor': reg_pipeline,
            'metadata': {
                'trained_at': yesterday_ds,
                'model_name': 'TF-IDF + Logistic/Ridge'
            }
        }
        #joblib.dump(class_pipeline, model_path)
        joblib.dump(model_pack, model_path)
        
        logging.info(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. Accuracy: {acc_test:.4f}, MSE: {mse_test:.4f}")

        save_model_data(class_pipeline)



def save_model_data(class_pipeline):

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ)
    # model_pack = joblib.load("/home/oleksandr/apps/comments-sentiment-analysis/models/sentiment_models_bundle.pkl")
    # class_pipeline = model_pack['classifier']

    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º TF-IDF –∏ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑ Pipeline
    tfidf = class_pipeline.named_steps['tfidf']
    clf = class_pipeline.named_steps['clf']

    # 2. –ü–æ–ª—É—á–∞–µ–º –°–ª–æ–≤–∞—Ä—å –∏ –í–µ—Å–∞ IDF
    # –°–ª–æ–≤–∞—Ä—å: —Å–ª–æ–≤–æ -> –∏–Ω–¥–µ–∫—Å
    # IDF: –∏–Ω–¥–µ–∫—Å -> –≤–µ—Å
    feature_names = tfidf.get_feature_names_out()
    idf_weights = tfidf.idf_

    df_tfidf = pd.DataFrame({
        'word': feature_names,
        'idf_weight': idf_weights
    }).sort_values(by='idf_weight', ascending=False)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å —Å IDF
    df_tfidf.to_csv("/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_tfidf.csv", index=False)

    # 3. –ü–æ–ª—É—á–∞–µ–º –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –†–µ–≥—Ä–µ—Å—Å–∏–∏
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (Positive, Negative, Neutral) –º–æ–¥–µ–ª—å —Ö—Ä–∞–Ω–∏—Ç –≤–µ—Å–∞ —Å–ª–æ–≤
    for i, label in enumerate(clf.classes_):
        coefs = clf.coef_[i]
        df_coefs = pd.DataFrame({
            'word': feature_names,
            'coefficient': coefs
        }).sort_values(by='coefficient', ascending=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ —Å–ª–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
        df_coefs.to_csv(f"/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_coefs_{label}.csv", index=False)

    # 4. –ü—Ä–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (C, ngram_range –∏ —Ç.–¥.)
    params = class_pipeline.get_params()
    with open("/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_params.txt", "w") as f:
        for key, value in params.items():
            f.write(f"{key}: {value}\n")

    print("üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV —Ñ–∞–π–ª—ã.")