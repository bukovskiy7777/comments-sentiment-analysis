import logging
import os
import matplotlib.pyplot as plt
from airflow.decorators import task
from airflow.providers.postgres.hooks.postgres import PostgresHook
import pandas as pd
import joblib
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, mean_squared_error, f1_score, 
    mean_absolute_error, ConfusionMatrixDisplay
)

@task
def train_sentiment_model(EXPERIMENT_NAME, ds=None, **context):
    # yesterday_ds = context['macros'].ds_add(ds, -1)
    yesterday_ds = ds
    pg_hook = PostgresHook(postgres_conn_id='postgres_ubuntu')
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    query = """
        SELECT c.text_display, s.label, s.score 
        FROM youtube_comments c
        JOIN comment_sentiment s ON c.comment_id = s.comment_id
    """
    df = pg_hook.get_pandas_df(query)

    if len(df) < 50:  # Grid Search —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        logging.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—É—Å–∫–∞ Grid Search.")
        return
    
    X = df['text_display']
    Y = df[['label', 'score']]

    X_train, X_test, y_train, y_test = train_test_split(
        X, Y, test_size=0.2, random_state=42, stratify=Y['label']
    )

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment(EXPERIMENT_NAME)

    with mlflow.start_run(run_name=f"train_grid_search_{yesterday_ds}"):
        
        # --- –®–ê–ì 1: Grid Search –¥–ª—è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ---
        # –ú—ã –∏—â–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã TF-IDF –∏ –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        base_class_pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(stop_words='english')),
            ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))
        ])

        param_grid = {
            'tfidf__max_features': [2500, 5000, 10000, 15000],
            'tfidf__ngram_range': [(1, 1), (1, 2)], # –£–Ω–∏–≥—Ä–∞–º–º—ã –∏ –±–∏–≥—Ä–∞–º–º—ã
            'tfidf__min_df': [2, 5],
            'clf__C': [0.1, 1.0, 10.0] # –°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        }

        logging.info("–ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
        grid_search = GridSearchCV(
            base_class_pipeline, 
            param_grid, 
            cv=3, 
            scoring='accuracy', 
            n_jobs=-1,
            verbose=1
        )
        grid_search.fit(X_train, y_train['label'])
        
        class_pipeline = grid_search.best_estimator_
        best_params = grid_search.best_params_

        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        y_pred_class = class_pipeline.predict(X_test)
        acc_test = accuracy_score(y_test['label'], y_pred_class)
        acc_train = accuracy_score(y_train['label'], class_pipeline.predict(X_train))
        f1 = f1_score(y_test['label'], y_pred_class, average='weighted')

        # --- –®–ê–ì 2: –†–µ–≥—Ä–µ—Å—Å–∏—è —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ TF-IDF ---
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã TF-IDF, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–±–µ–¥–∏–ª–∏ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        reg_pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                stop_words='english',
                max_features=best_params['tfidf__max_features'],
                ngram_range=best_params['tfidf__ngram_range'],
                min_df=best_params['tfidf__min_df']
            )),
            ('reg', Ridge())
        ])
        
        reg_pipeline.fit(X_train, y_train['score'])
        y_pred_reg = reg_pipeline.predict(X_test)
        
        mse_test = mean_squared_error(y_test['score'], y_pred_reg)
        mse_train = mean_squared_error(y_train['score'], reg_pipeline.predict(X_train))
        mae = mean_absolute_error(y_test['score'], y_pred_reg)

        # --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow ---
        mlflow.log_params(best_params)
        mlflow.log_param("grid_search_status", "completed")
        
        mlflow.log_metric("accuracy_train", acc_train)
        mlflow.log_metric("accuracy_test", acc_test)
        mlflow.log_metric("acc_gap", abs(acc_test - acc_train))
        mlflow.log_metric("f1_score", f1)
        
        mlflow.log_metric("mse_train", mse_train)
        mlflow.log_metric("mse_test", mse_test)
        mlflow.log_metric("mae_score", mae)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ Confusion Matrix –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç
        fig, ax = plt.subplots(figsize=(8, 6))
        ConfusionMatrixDisplay.from_predictions(
            y_test['label'], y_pred_class, 
            display_labels=class_pipeline.classes_, 
            cmap=plt.cm.Blues, ax=ax
        )
        plt.title(f"Confusion Matrix {yesterday_ds}")
        mlflow.log_figure(fig, "confusion_matrix.png")
        plt.close(fig)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ MLflow
        mlflow.sklearn.log_model(class_pipeline, "classifier_model")
        mlflow.sklearn.log_model(reg_pipeline, "regressor_model")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –±–∞–Ω–¥–ª–∞ –¥–ª—è FastAPI
        model_path = "/home/oleksandr/apps/comments-sentiment-analysis/models/sentiment_models_bundle.pkl"
        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        model_pack = {
            'classifier': class_pipeline,
            'regressor': reg_pipeline,
            'metadata': {
                'trained_at': yesterday_ds,
                'model_name': 'TF-IDF GridSearch Optimized',
                'best_params': best_params
            }
        }
        joblib.dump(model_pack, model_path)
        
        logging.info(f"Grid Search –∑–∞–≤–µ—Ä—à–µ–Ω. –õ—É—á—à–∞—è Accuracy: {acc_test:.4f}. Params: {best_params}")

        save_model_data(class_pipeline)



def save_model_data(class_pipeline):

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ)
    # model_pack = joblib.load("/home/oleksandr/apps/comments-sentiment-analysis/models/sentiment_models_bundle.pkl")
    # class_pipeline = model_pack['classifier']

    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º TF-IDF –∏ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑ Pipeline
    tfidf = class_pipeline.named_steps['tfidf']
    clf = class_pipeline.named_steps['clf']

    # 2. –ü–æ–ª—É—á–∞–µ–º –°–ª–æ–≤–∞—Ä—å –∏ –í–µ—Å–∞ IDF
    # –°–ª–æ–≤–∞—Ä—å: —Å–ª–æ–≤–æ -> –∏–Ω–¥–µ–∫—Å
    # IDF: –∏–Ω–¥–µ–∫—Å -> –≤–µ—Å
    feature_names = tfidf.get_feature_names_out()
    idf_weights = tfidf.idf_

    df_tfidf = pd.DataFrame({
        'word': feature_names,
        'idf_weight': idf_weights
    }).sort_values(by='idf_weight', ascending=False)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å —Å IDF
    df_tfidf.to_csv("/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_tfidf.csv", index=False)

    # 3. –ü–æ–ª—É—á–∞–µ–º –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –†–µ–≥—Ä–µ—Å—Å–∏–∏
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (Positive, Negative, Neutral) –º–æ–¥–µ–ª—å —Ö—Ä–∞–Ω–∏—Ç –≤–µ—Å–∞ —Å–ª–æ–≤
    for i, label in enumerate(clf.classes_):
        coefs = clf.coef_[i]
        df_coefs = pd.DataFrame({
            'word': feature_names,
            'coefficient': coefs
        }).sort_values(by='coefficient', ascending=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ —Å–ª–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
        df_coefs.to_csv(f"/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_coefs_{label}.csv", index=False)

    # 4. –ü—Ä–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (C, ngram_range –∏ —Ç.–¥.)
    params = class_pipeline.get_params()
    with open("/home/oleksandr/apps/comments-sentiment-analysis/models/models_data/model_debug_params.txt", "w") as f:
        for key, value in params.items():
            f.write(f"{key}: {value}\n")

    print("üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV —Ñ–∞–π–ª—ã.")
